model:
  base_url: "http://localhost:8099/v1"
  model_name: "QWEN3-32b-AWQ"  # vLLM启动时指定的模型名
  max_tokens: 32768            # Qwen3支持32K上下文
  temperature: 0.7
  timeout: 120
  tokenizer_path: "/mnt/d/projects/Open-Models"